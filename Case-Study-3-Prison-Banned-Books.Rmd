---
title: "Case-Study-3-Prison-Banned-Books"
author: "Salimah Ismail"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(reshape2)
library(wordcloud)
library(RColorBrewer)
library(tm)
library(htmltools)
```

## Case Study #3 Books Banned in State Prisons (2022)

This [data set from The Marshall Project](https://observablehq.com/@themarshallproject/prison-banned-books) was shared from the [Data is Plural](https://www.data-is-plural.com/archive/2023-01-04-edition/) website. As prison systems in the United States are infamously known for their preference for punishment over rehabilitation, understanding more about the banned books would be enlightening to the preferences and biases of the country.   

## The Task
Look at trends around banned books in prisions in the United States and identify any common trends or important outliers. 

## Available Information
Information from examined from this data set include:

* Title of the Book
* Author
* Month / Year the book was banned 
* Justification for banning the book 
* State postal code

### Limitations
Information is not provided by all states and many states omit to share a reason why the book was banned. Information on Authors is also limited.    

```{r load-dataset, echo=FALSE, results='hide', message=FALSE}
books <- read_csv("C:/Users/salim/Dropbox/Ismail/GWG-Data-Analysis-Capstone-Projects/Banned Books Data/banned_book_data_combined_lists.csv")
```

## Visualizations

*Count of Prison Banned Books by State from 1812 - 2022*

<div class='tableauPlaceholder' id='viz1698355144944' style='position: relative'><noscript><a href='#'><img alt='Count of Prison Banned Books by State from 1815-2022 ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ca&#47;Case-Study-3-Prison-Banned-Books&#47;Sheet1&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='Case-Study-3-Prison-Banned-Books&#47;Sheet1' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ca&#47;Case-Study-3-Prison-Banned-Books&#47;Sheet1&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1698355144944');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>

*Years when Book Banning Occurred*


```{r year-banned, echo=FALSE, warning=FALSE}
books %>% 
  group_by(year, state_arc) %>% 
  summarise(number_of_books = n(), .groups = "drop") %>% 
  ggplot(aes(x = year, y = number_of_books, fill = state_arc)) + 
  geom_col(position = "stack") +
  coord_cartesian(xlim = c(1990, 2022)) +
  labs(title = "Number of Prison Banned Books by Year", x = "Year", y = "Number of Books", fill = "State") +
  scale_fill_manual(name="State", labels=c("Arizona", "California", "Connecticut", "Florida", "Georgia", "Iowa", "Illinois","Kansas", "Michigan", "Missouri", "Montana", "North Carolina","Rhode Island", "Texas", "Wisconsin"), values = c("#1f77b4","#aec7e8","#ff7f0e","#ffbb78","#2ca02c","#98df8a","#d62728","#ff9896","#9467bd","#c5b0d5","#8c564b","#c49c94","#e377c2","#17becf","#7f7f7f"))
```



*Wordcloud of Book Titles*

```{r wordcloud-titles, echo=FALSE, warning=FALSE}
title <- books$publication
title_corpus <- Corpus(VectorSource(title)) 

title_corpus <- title_corpus %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)

title_corpus <- tm_map(title_corpus, content_transformer(tolower))
title_corpus <- tm_map(title_corpus, removeWords, stopwords("english"))

dtm <- TermDocumentMatrix(title_corpus)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix), decreasing=TRUE)
df <- data.frame(word = names(words), freq=words)

set.seed(1234) # for reproducibility 

wordcloud(words = df$word, freq = df$freq, min.freq = 200,
max.words=200, random.order=FALSE, rot.per=0.10, colors=brewer.pal(8, "Dark2"))
title(main="Wordcloud of Prison Banned Books Titles*\n\n", sub="*Words that appear at least 200 times.")

```



*Top 10 Banned Titles*

```{r top-10-titles, echo=FALSE, warning=FALSE}
# First, group by 'publication' and 'state_arc', then summarise the data
grouped_books <- books %>%
  group_by(publication, state_arc) %>%
  mutate(state_arc = ifelse(state_arc == "fl", "Florida", state_arc)) %>%
  summarise(n = n(), .groups = "drop")

# Then, arrange the data in descending order of 'n' and select the top 10 publications
top_titles <- grouped_books %>%
  arrange(desc(n)) %>%
  slice_head(n = 10)

colnames(top_titles) <- c("Title", "State Where Title Appeared", "Count")

knitr::kable(top_titles)
```



*Map of States that Provide a Reason for Banning Books and % of Books that have a Reason*
```{r map of reasons, echo=FALSE, warning=FALSE}
#Determining Unique reasons provided for why books are banned: 
#unique_reasons <- c()
#for (i in 1:dim(books)[1]) {if (books$state_arc[i] == "ia" & !is.na(books$reason[i])){unique_reasons <- c(unique_reasons, books$reason[i])}}
#print(unique(unique_reasons))
```
<center>
<iframe src="https://public.tableau.com/views/Case-Study-3-Prison-Banned-Books-Reason/Sheet1?:language=en-US&:display_count=n&:origin=viz_share_link" width="800" height="627" frameborder="0"></iframe>
</center>

*Wordcloud of Banning Reasons*

```{r wordcloud-reasons, echo=FALSE, warning=FALSE}
reasons <- books$reason
reason_corpus <- Corpus(VectorSource(reasons)) 

reason_corpus <- reason_corpus %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)

reason_corpus <- tm_map(reason_corpus, content_transformer(tolower))

# Define a vector of words to remove
remove_words <- c("contain", "contains", "contained", "containing", "excluded", "book", "books") # Add more variations if needed

# Remove stopwords and custom words
reason_corpus <- tm_map(reason_corpus, removeWords, c(stopwords("english"), remove_words))

# Create a function for bigram tokenization
#BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 5))

# Create a term-document matrix with bigrams
dtm_r <- TermDocumentMatrix(reason_corpus) 
                            #control = list(tokenize = BigramTokenizer))
matrix_r <- as.matrix(dtm_r)
words_r <- sort(rowSums(matrix_r), decreasing=TRUE)
df_r <- data.frame(word_r = names(words_r), freq_r=words_r)

set.seed(1234) # for reproducibility 

wordcloud(words = df_r$word_r, freq = df_r$freq_r, min.freq = 250,
max.words=200, random.order=FALSE, rot.per=0.01, colors=brewer.pal(8, "Dark2"))
title(main="Wordcloud of Prison Banned Books Reasons*\n\n", sub="*Words/Phrases that appear at least 250 times.")

```


## Insights
-Florida has banned substantially more books than any of the other recorded states and was one of the first to start the mass book banning. -Book banning increased drastically in 2012. 
-The most commonly banned books are pornographic in nature. 
-Not all the states provided reasons for banning the books, and those who did split between having some standardized reasons and seeming to be at a more individual discretion. 

